// lib/services/face_detection_service.dart (Substituir o ficheiro)

import 'dart:io';

import 'package:flutter/foundation.dart';
import 'package:google_mlkit_face_detection/google_mlkit_face_detection.dart';
import 'package:sentry_flutter/sentry_flutter.dart';

import 'platform_camera_utils.dart';

/// Singleton respons√°vel por detectar rostos utilizando o Google MLKit.
///
/// OTIMIZADO PARA DETEC√á√ÉO EM FOTOS (n√£o ao vivo) - m√°xima precis√£o.
/// Configura√ß√£o adaptativa por plataforma (iOS mais sens√≠vel que Android).
class FaceDetectionService {
  FaceDetectionService._();

  static final FaceDetectionService instance = FaceDetectionService._();

  FaceDetector? _faceDetector;
  final PlatformCameraUtils _platformUtils = PlatformCameraUtils.instance;

  FaceDetector _ensureDetector() {
    if (_faceDetector != null) {
      return _faceDetector!;
    }

    // ‚úÖ CONFIGURA√á√ÉO MAXIMIZADA PARA FOTOS (N√ÉO AO VIVO)
    final bool isIOS = _platformUtils.isIOS;

    final minFaceSize = isIOS ? 0.05 : 0.08;
    final performanceMode = FaceDetectorMode.accurate;

    Sentry.captureMessage(
      'üîß DETECTOR: Criando FaceDetector (FOTOS v2 - Simplificado)',
      level: SentryLevel.info,
      withScope: (scope) {
        scope.setTag('platform', isIOS ? 'iOS' : 'Android');
        scope.setTag('detector_mode', 'accurate_simplified'); // ‚úÖ v2
        scope.setTag('min_face_size', minFaceSize.toString());
        scope.setContexts('detector_config', {
          'min_face_size': minFaceSize,
          'performance_mode': 'accurate',
          'enable_landmarks': true,     // ‚úÖ Essencial
          'enable_classification': false, // ‚úÖ Simplificado
          'enable_contours': false,     // ‚úÖ Simplificado
          'purpose': 'photo_processing_not_live',
        });
      },
    );

    // ‚úÖ CONFIGURA√á√ÉO ATUALIZADA (v2) - MANT√âM PRECIS√ÉO, REMOVE EXTRAS
    _faceDetector = FaceDetector(
      options: FaceDetectorOptions(
        performanceMode: performanceMode,
        enableLandmarks: true,
        enableContours: false,
        enableClassification: false,
        enableTracking: false,
        minFaceSize: minFaceSize,
      ),
    );

    debugPrint('üéØ [FaceDetection] Configurado para FOTOS v2 ${isIOS ? "iOS" : "Android"} '
        '- minFaceSize: $minFaceSize, mode: $performanceMode '
        '- Landmarks: true, Classification: false, Contours: false'); // ‚úÖ v2

    return _faceDetector!;
  }

  /// Detecta rostos em um [InputImage] gen√©rico.
  /// Esta √© agora a √öNICA forma de usar este servi√ßo.
  Future<List<Face>> detect(InputImage input) async {
    final detector = _ensureDetector();
    try {
      final faces = await detector.processImage(input);
      debugPrint('‚úÖ [FaceDetection] Processado. Faces: ${faces.length}');
      return faces;
    } catch (e, stackTrace) {
      debugPrint('‚ùå [FaceDetection] Erro ao processar imagem: $e');
      await Sentry.captureException(
        e,
        stackTrace: stackTrace,
        hint: Hint.withMap({
          'context': 'FaceDetectionService.detect()',
          'image_size': '${input.metadata?.size.width}x${input.metadata?.size.height}',
          'image_rotation': input.metadata?.rotation.name,
          'image_format': input.metadata?.format.name,
          'detection_type': 'photo_processing',
        }),
      );
      rethrow;
    }
  }

  // ‚ùå REMOVIDO: detectFromFile(File file)
  // Esta fun√ß√£o usava InputImage.fromFile(), que √© a fonte dos problemas no iOS.
  // Ao remov√™-la, for√ßamos o FaceImageProcessor a fazer a convers√£o correta.

  // ‚ùå REMOVIDO: detectFromPath(String path)
  // Tamb√©m usava InputImage.fromFilePath(), igualmente problem√°tico.

  void dispose() {
    _faceDetector?.close();
    _faceDetector = null;
    debugPrint('üóëÔ∏è [FaceDetection] Detector de fotos liberado.');
  }
}