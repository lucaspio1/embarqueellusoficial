import 'dart:io';
import 'dart:typed_data';

import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import 'package:flutter/services.dart';
import 'package:google_mlkit_commons/google_mlkit_commons.dart';
import 'package:path_provider/path_provider.dart';
import 'package:sentry_flutter/sentry_flutter.dart';

import 'native_face_service.dart';
import 'platform_camera_utils.dart';

/// Servi√ßo PRINCIPAL para captura √∫nica de foto com detec√ß√£o facial.
///
/// NOVA ARQUITETURA (Migra√ß√£o Nativa):
/// 1. Inicializa√ß√£o da c√¢mera
/// 2. Captura de uma √∫nica foto (n√£o streaming)
/// 3. DELEGA√á√ÉO para NativeFaceService (processamento nativo iOS/Android)
/// 4. Retorno do recorte como Uint8List pronto para embeddings
///
/// RESPONSABILIDADE √öNICA:
/// - FaceCaptureService: Apenas gerencia c√¢mera e captura foto
/// - NativeFaceService: Ponte para processamento nativo (corre√ß√£o EXIF + detec√ß√£o + recorte)
/// - C√≥digo Nativo (Swift/Kotlin): Processamento completo usando ML Kit nativo
///
/// BENEF√çCIOS:
/// ‚úÖ Corre√ß√£o de EXIF nativa (UIImage no iOS, ExifInterface no Android)
/// ‚úÖ Detec√ß√£o facial mais r√°pida e precisa (SDK nativo do ML Kit)
/// ‚úÖ Resolve completamente o bug do iOS com InputImage.fromFile()
/// ‚úÖ C√≥digo modular e test√°vel
/// ‚úÖ Compat√≠vel com iOS 15.5+ e Android
///
/// DEPEND√äNCIAS:
/// - NativeFaceService: ponte para processamento nativo
/// - PlatformCameraUtils: utilit√°rios multiplataforma
class FaceCaptureService {
  FaceCaptureService._();

  static final FaceCaptureService instance = FaceCaptureService._();

  final NativeFaceService _nativeService = NativeFaceService.instance;
  final PlatformCameraUtils _platformUtils = PlatformCameraUtils.instance;

  CameraController? _controller;
  bool _isInitialized = false;

  /// Inicializa a c√¢mera para captura.
  ///
  /// [useFrontCamera] - true para c√¢mera frontal, false para traseira
  Future<void> initCamera({bool useFrontCamera = false}) async {
    try {
      await Sentry.captureMessage(
        'üì∑ FACE_CAPTURE: Inicializando c√¢mera',
        level: SentryLevel.info,
        withScope: (scope) {
          scope.setTag('platform', _platformUtils.isIOS ? 'iOS' : 'Android');
          scope.setContexts('camera_init', {
            'camera_type': useFrontCamera ? 'front' : 'back',
          });
        },
      );

      final cameras = await availableCameras();

      if (cameras.isEmpty) {
        throw Exception('Nenhuma c√¢mera dispon√≠vel no dispositivo');
      }

      final camera = cameras.firstWhere(
        (c) => c.lensDirection ==
            (useFrontCamera ? CameraLensDirection.front : CameraLensDirection.back),
        orElse: () => cameras.first,
      );

      await Sentry.captureMessage(
        'üì± FACE_CAPTURE: C√¢mera selecionada',
        level: SentryLevel.info,
        withScope: (scope) {
          scope.setContexts('camera_selected', {
            'camera_name': camera.name,
            'camera_direction': camera.lensDirection.toString(),
            'sensor_orientation': camera.sensorOrientation,
          });
        },
      );

      _controller = CameraController(
        camera,
        ResolutionPreset.high,
        enableAudio: false,
        imageFormatGroup: _platformUtils.isIOS
            ? ImageFormatGroup.bgra8888
            : ImageFormatGroup.yuv420,
      );

      await _controller!.initialize();
      _isInitialized = true;

      await Sentry.captureMessage(
        '‚úÖ FACE_CAPTURE: C√¢mera inicializada com sucesso',
        level: SentryLevel.info,
        withScope: (scope) {
          scope.setTag('platform', _platformUtils.isIOS ? 'iOS' : 'Android');
          scope.setContexts('camera_initialized', {
            'resolution': ResolutionPreset.high.toString(),
            'format': _platformUtils.expectedImageFormat.toString(),
          });
        },
      );
    } catch (e, stackTrace) {
      await Sentry.captureException(
        e,
        stackTrace: stackTrace,
        hint: Hint.withMap({
          'context': 'Erro ao inicializar c√¢mera para captura facial',
          'platform': _platformUtils.platformDescription,
        }),
      );
      rethrow;
    }
  }

  /// Captura uma foto, detecta a face e retorna o recorte facial.
  ///
  /// NOVA ARQUITETURA (Migra√ß√£o Nativa):
  /// - FaceCaptureService: Apenas captura a foto
  /// - NativeFaceService: Ponte para c√≥digo nativo
  /// - C√≥digo Nativo (Swift/Kotlin): Corrige EXIF, detecta e recorta usando ML Kit nativo
  ///
  /// Retorna [FaceCaptureResult] contendo:
  /// - croppedFaceBytes: Uint8List da face recortada (pronta para embeddings)
  /// - boundingBox: Coordenadas da face detectada
  /// - imagePath: Caminho da imagem original capturada
  ///
  /// Lan√ßa exce√ß√£o se:
  /// - C√¢mera n√£o foi inicializada
  /// - Nenhuma face foi detectada
  /// - Erro no processamento
  Future<FaceCaptureResult> captureAndDetectFace() async {
    try {
      if (_controller == null || !_isInitialized) {
        throw Exception('C√¢mera n√£o foi inicializada. Chame initCamera() primeiro.');
      }

      await Sentry.captureMessage(
        'üì∏ FACE_CAPTURE: Capturando foto',
        level: SentryLevel.info,
      );

      // PASSO 1: Capturar foto (responsabilidade √∫nica do FaceCaptureService)
      final XFile file = await _controller!.takePicture();
      final String imagePath = file.path;

      await Sentry.captureMessage(
        '‚úÖ FACE_CAPTURE: Foto capturada | Delegando processamento para NativeFaceService',
        level: SentryLevel.info,
        withScope: (scope) {
          scope.setTag('platform', _platformUtils.isIOS ? 'iOS' : 'Android');
          scope.setContexts('photo_captured', {
            'image_path': imagePath,
            'file_exists': await File(imagePath).exists(),
          });
        },
      );

      // PASSO 2: Delegar TODO processamento para o c√≥digo nativo
      // O c√≥digo nativo agora √© respons√°vel por:
      // - Corrigir EXIF automaticamente (UIImage/ExifInterface)
      // - Detectar face usando ML Kit nativo
      // - Recortar face
      // - Redimensionar para 112x112
      // - Converter para JPEG
      final nativeResult = await _nativeService.detectAndCropFace(imagePath);

      await Sentry.captureMessage(
        '‚úÖ FACE_CAPTURE: Captura e processamento conclu√≠dos',
        level: SentryLevel.info,
        withScope: (scope) {
          scope.setTag('platform', _platformUtils.isIOS ? 'iOS' : 'Android');
          scope.setContexts('capture_complete', {
            'cropped_bytes_size': nativeResult.croppedFaceBytes.length,
            'bbox_width': nativeResult.boundingBox.width.toInt(),
            'bbox_height': nativeResult.boundingBox.height.toInt(),
          });
        },
      );

      return FaceCaptureResult(
        croppedFaceBytes: nativeResult.croppedFaceBytes,
        boundingBox: nativeResult.boundingBox,
        imagePath: imagePath,
      );
    } catch (e, stackTrace) {
      await Sentry.captureException(
        e,
        stackTrace: stackTrace,
        hint: Hint.withMap({
          'context': 'Erro ao capturar e detectar face',
          'platform': _platformUtils.platformDescription,
        }),
      );
      rethrow;
    }
  }

  /// Retorna o CameraController para pr√©via da c√¢mera na UI.
  CameraController? get controller => _controller;

  /// Verifica se a c√¢mera est√° inicializada.
  bool get isInitialized => _isInitialized;

  /// Libera recursos da c√¢mera.
  Future<void> dispose() async {
    try {
      await _controller?.dispose();
      _controller = null;
      _isInitialized = false;

      await Sentry.captureMessage(
        'üóëÔ∏è FACE_CAPTURE: Recursos da c√¢mera liberados',
        level: SentryLevel.info,
      );
    } catch (e, stackTrace) {
      await Sentry.captureException(
        e,
        stackTrace: stackTrace,
        hint: Hint.withMap({
          'context': 'Erro ao liberar recursos da c√¢mera',
        }),
      );
    }
  }

  /// Retorna a rota√ß√£o da imagem baseada na c√¢mera e orienta√ß√£o.
  InputImageRotation getRotation({
    DeviceOrientation orientation = DeviceOrientation.portraitUp,
  }) {
    if (_controller == null) {
      return InputImageRotation.rotation0deg;
    }

    return _platformUtils.getImageRotation(
      camera: _controller!.description,
      deviceOrientation: orientation,
    );
  }
}

/// Resultado da captura facial.
class FaceCaptureResult {
  /// Bytes da face recortada (JPEG, 112x112) - pronta para gerar embeddings
  final Uint8List croppedFaceBytes;

  /// Coordenadas da bounding box da face na imagem original
  final Rect boundingBox;

  /// Caminho da imagem original capturada
  final String imagePath;

  const FaceCaptureResult({
    required this.croppedFaceBytes,
    required this.boundingBox,
    required this.imagePath,
  });

  @override
  String toString() {
    return 'FaceCaptureResult('
        'croppedFaceBytes: ${croppedFaceBytes.length} bytes, '
        'boundingBox: ${boundingBox.width.toInt()}x${boundingBox.height.toInt()}, '
        'imagePath: $imagePath'
        ')';
  }
}
